// Groq AI Integration with Llama 3.1 8B
const API_KEY = import.meta.env.VITE_GROQ;
const API_URL = 'https://api.groq.com/openai/v1/chat/completions';

// Function to extract JSON from text more robustly
const extractJSON = (text) => {
  // Try to parse the entire text first
  try {
    return JSON.parse(text);
  } catch (e) {
    // If that fails, try to find JSON objects in the text
  }

  // Try to find JSON with non-greedy matching
  const matches = text.match(/\{[\s\S]*?\}/g);
  if (matches && matches.length > 0) {
    // Try each match, starting from the longest (likely the main response)
    const sortedMatches = matches.sort((a, b) => b.length - a.length);
    for (const match of sortedMatches) {
      try {
        return JSON.parse(match);
      } catch (e) {
        continue;
      }
    }
  }

  // If we still can't find valid JSON, throw an error
  throw new Error('N√£o foi poss√≠vel extrair JSON v√°lido da resposta');
};

export const invokeOpenAI = async (prompt, responseJsonSchema = null) => {
  try {
    // Sem API key = erro (sem fallback!)
    if (!API_KEY) {
      console.error('‚ùå VITE_GROQ n√£o configurada');
      throw new Error('API de IA n√£o configurada. Configure VITE_GROQ para usar an√°lises.');
    }

    // Construir o prompt com instru√ß√µes de JSON se necess√°rio
    let finalPrompt = prompt;
    if (responseJsonSchema) {
      finalPrompt = `${prompt}\n\nResponda APENAS com um JSON v√°lido que corresponda a este schema: ${JSON.stringify(responseJsonSchema)}\n\nN√£o inclua texto antes ou depois do JSON. Retorne APENAS o objeto JSON, nada mais.`;
    }

    const requestBody = {
      model: 'llama-3.1-8b-instant',
      messages: [
        {
          role: 'system',
          content: 'Voc√™ √© um assistente financeiro experiente. Forne√ßa an√°lises detalhadas e precisas em portugu√™s brasileiro. Quando pedido para retornar JSON, retorne APENAS o JSON v√°lido, sem texto adicional.'
        },
        {
          role: 'user',
          content: finalPrompt
        }
      ],
      temperature: 0.5,
      max_tokens: 2048
    };

    const response = await fetch(API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${API_KEY}`
      },
      body: JSON.stringify(requestBody)
    });

    if (!response.ok) {
      const error = await response.json();
      console.error('Groq API Error:', error);
      throw new Error(error.error?.message || 'Erro na API Groq');
    }

    const data = await response.json();
    
    if (!data.choices?.[0]?.message?.content) {
      throw new Error('Resposta vazia da API');
    }

    const textContent = data.choices[0].message.content.trim();
    
    // Se esperamos JSON, parse
    if (responseJsonSchema) {
      try {
        const result = extractJSON(textContent);
        console.log('‚úÖ JSON v√°lido extra√≠do da IA:', JSON.stringify(result).substring(0, 200));
        return result;
      } catch (e) {
        console.error('‚ùå Erro ao extrair JSON:', e.message);
        console.error('üìù Resposta completa da IA:', textContent);
        throw new Error('Resposta JSON inv√°lida da IA');
      }
    }
    
    return textContent;
  } catch (error) {
    console.error('Groq Request Error:', error.message);
    throw error;
  }
};
